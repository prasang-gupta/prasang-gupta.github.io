<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HTML | Prasang Gupta</title>
    <link>https://prasang-gupta.github.io/tag/html/</link>
      <atom:link href="https://prasang-gupta.github.io/tag/html/index.xml" rel="self" type="application/rss+xml" />
    <description>HTML</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2021 Prasang Gupta</copyright><lastBuildDate>Thu, 01 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://prasang-gupta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>HTML</title>
      <link>https://prasang-gupta.github.io/tag/html/</link>
    </image>
    
    <item>
      <title>HTML UI element extraction</title>
      <link>https://prasang-gupta.github.io/project/websiteuidetection/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/websiteuidetection/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#58D68D&#34;&gt;We achieved&lt;/span&gt; &lt;span style=&#34;color:#52BE80;font-style:bold;font-size:120%&#34;&gt;3rd rank&lt;/span&gt; &lt;span style=&#34;color:#58D68D&#34;&gt;in the hackathon.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this hackathon was to localise and identify several different HTML UI elements in hand-drawn wireframe drawings of websites as well as for screenshots of real websites.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The dataset provided for the hackathon contained about 3200 wireframe drawings of websites. The goal was to identify the different HTML UI elemnents present in the image, such as &amp;ldquo;Text Box&amp;rdquo;, &amp;ldquo;Button&amp;rdquo;, &amp;ldquo;Image&amp;rdquo;, etc. Hence, it boiled down to an object detection problem. It also included another dataset containing screenshots of real websites. The problem remained the same for both the datasets.&lt;/p&gt;
&lt;p&gt;We used several different Object Detection techniques and decided on using the just released SOTA model YOLOv5. We tried different flavours of YOLOv5 and since inference time was not a bar, we went ahead with the XL version of the same to boost performance. We also used pre-trained weights and performed a LR scheduler study to boost the scores even further.&lt;/p&gt;
&lt;p&gt;We also observed that our model was giving out good predictions for the common elements with high confidences, but was not giving outputs for the more uncommon elements. Hence, we performed a study to change the confidence cutoff levels to optimise it for the use case and adjust it according to the distribution in the data. This allowed us to achieve near-perfect performance level of 0.95 F1 score on the validation set.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The solution built was performing really good on unseen test images managing an mAP value of 0.82. This model was later swapped with the last year&amp;rsquo;s model in the already developed pipeline to allow rapid prototyping of websites and dashboards.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HTML Atomic UI Elements Extraction from Hand-Drawn Website Images using Mask-RCNN and novel Multi-Pass Inference Technique</title>
      <link>https://prasang-gupta.github.io/publication/clef2020/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/publication/clef2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HTML UI element extraction</title>
      <link>https://prasang-gupta.github.io/project/wireframeuidetection/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/wireframeuidetection/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#58D68D&#34;&gt;We achieved&lt;/span&gt; &lt;span style=&#34;color:#52BE80;font-style:bold;font-size:120%&#34;&gt;3rd rank&lt;/span&gt; &lt;span style=&#34;color:#58D68D&#34;&gt;in the hackathon.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this hackathon was to localise and identify several different HTML UI elements in hand-drawn wireframe drawings of websites.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The dataset provided for the hackathon contained about 3000 wireframe drawings of websites. The goal was to identify the different HTML UI elemnents present in the image, such as &amp;ldquo;Text Box&amp;rdquo;, &amp;ldquo;Button&amp;rdquo;, &amp;ldquo;Image&amp;rdquo;, etc. Hence, it boiled down to an object detection problem.&lt;/p&gt;
&lt;p&gt;We tried using several Object Detection algorithms like YOLO, R-CNN and Mask-RCNN and decided on Mask-RCNN as it was providing us with the best results. However, one thing we observed in our outputs was that our Precision scores were good, but the model was lacking in Recall bringing the whole F1 down. To solve this problem, we came up with a novel technique &amp;ldquo;Multi-Pass Inference&amp;rdquo; that booosted our recall scores.&lt;/p&gt;
&lt;p&gt;The technique involves running the image through the model multiple times, each time taking note of the objects that are already detected and removing them for subsequent passes. This forced the model to predict more instances of the elements in the image. We smarlty combined the objects detected in multiple passes to overall boost the recall score of our model helping us to take a podium spot in the leaderboard.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The solution built was performing really good on unseen test images managing an mAP (IoU &amp;gt; 0.5) score of 64.12. This solution was later implemented into a pipeline to allow rapid prototyping of websites and dashboards.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
