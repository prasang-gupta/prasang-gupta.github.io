<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IoT | Prasang Gupta</title>
    <link>https://prasang-gupta.github.io/tag/iot/</link>
      <atom:link href="https://prasang-gupta.github.io/tag/iot/index.xml" rel="self" type="application/rss+xml" />
    <description>IoT</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2021 Prasang Gupta</copyright><lastBuildDate>Mon, 01 Nov 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://prasang-gupta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>IoT</title>
      <link>https://prasang-gupta.github.io/tag/iot/</link>
    </image>
    
    <item>
      <title>Model Parallelism for Inference at edge</title>
      <link>https://prasang-gupta.github.io/project/modelparallelism/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/modelparallelism/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project was to create a solution that can be used to train a model that can be split into multiple pieces and can be run in parallel on multiple separate devices.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The architecture used was the recently published DeCNN (Decoupled CNN) network. The authors had used GConv with Channel Shuffle and added other network and OS level modifications to improve the performance of the decoupled architecture. For initial testing, we only focused on Scheme 1 and ignored other optimisations to establish a baseline.&lt;/p&gt;
&lt;p&gt;We used the tiny imagenet dataset and Resnet-34 model for testing and comparing the standard CNN results with DeCNN. We compared based on the performance (accuracy metrics) and the time taken to run inference on a fixed batch of data. It was found that there was a performance decrease by using DeCNN as some of the information is lost while doing channel shuffling. To counter that, we used 1.5x kernels as in the standard CNN to keep the performance comparable. Even while using just the Scheme 1 mentioned above, we got about 15% bump up in inference speeds with just 2 devices. We expect that this gap would increase with larger models and with more number of parallel devices.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The solution developed can be used to train models specifically for running on smaller edge devices. This is especially helpful as no single device can hold the full model in memory at the edge due to size and compute limitations and this would help in running bigger and better models at the edge with no added requirement of a heavy compute engine deployment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Worlds.io</title>
      <link>https://prasang-gupta.github.io/project/worldsio/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/worldsio/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this study was to test out some of the features offered by Worlds.io and create a generalised digital twin solution that can be leveraged in future projects. This would include generating a digital replication of their current environment and answer some of the questions based off of that with some additional analysis to allow clients to make better oeprational and strategic decisions.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;animation.gif&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We took the live footage provided by the vendor in New York City&amp;rsquo;s Bryant Park as a case study. A YOLO model was put on the raw camera footage to capture some common objects like people, bins, animals (pets) etc. This was then converted into a streaming data format and sent to cloud with approximate latitude and longitude values as provided by the vendor based on the camera&amp;rsquo;s location and field of view. These lat-lon values were then converted into cartesian coordinates, effectively treating Bryant park in a 2D plane for getting the data ready for digital twin studies. We also created a few zones and mapped the coordinates accordingly.&lt;/p&gt;
&lt;p&gt;The conversion to cartesian coordinates helped us to map the pedestrian movement patterns in the field of view. Additionally, we also extracted other information to answer questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How many people are passing through our zones in the park?&lt;/li&gt;
&lt;li&gt;How long are people generally in the park for?&lt;/li&gt;
&lt;li&gt;How many people are sitting in the park?&lt;/li&gt;
&lt;li&gt;How many people are walking babies/strollers?&lt;/li&gt;
&lt;li&gt;How many tourists/suitcases ?&lt;/li&gt;
&lt;li&gt;Are people riding bikes in the park?&lt;/li&gt;
&lt;li&gt;How many deliveries with carts are made?&lt;/li&gt;
&lt;li&gt;How many people are walking pets in the park?&lt;/li&gt;
&lt;li&gt;How many people per hour, walking speed, which way are they going,&lt;/li&gt;
&lt;li&gt;What % of people are stopping?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We were able to run analytics on the video feed and the derived variables. Also, we were able to generate a digital twin using the converted coordinates. This helped us build capability for any future projects that might entail the use of these technologies.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Edge Compute</title>
      <link>https://prasang-gupta.github.io/project/distributededge/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/distributededge/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this study was to build a system to distribute compute load across different resources present on the edge. It also involved testing the built system with a dummy exercise and find out the robustness of the system and any additional points that might need to be taken care of before actually attempting a client project in this domain.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We built out a system for distributed edge compute using microk8s, a micro kubernetes engine. We paired it with metalb, a load balancer and dashboarding, resource tracking and reporting tools like grafana and prometheus. To simulate an edge environment, a local ensemble of devices was created and connected together on the same network. A total of 3 devices were included in the network including a raspbery pi, a windows laptop and an edge compute appliance. For testing out the pipeline, we ran a simple object detection model on all the devices using tensorflow serving.&lt;/p&gt;
&lt;p&gt;While testing, we also came across several limitations of the architecture. The first is that the compute power was very skewed within the networks (x86 devices were orders of magnitude faster than ARM). This lead to bottlenecking at times even with the load balancer. We also realised that running a full object detection model on small devices was not a great idea due to the compute and memory limitations of each device.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The system built was a demonstration that multiple unused devices can be pooled together at the edge to increase the overall compute capabilities, reducing the lag of transferring data to and from the cloud. Apart from reducing latency, it also helps in keeping the data secure as everything is happening locally. This also ensures that no single edge device is overutilised hampering the pipeline.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fingervein Detection</title>
      <link>https://prasang-gupta.github.io/project/fingervein/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/fingervein/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project was to build out a fully functional proof of concept for the fingervein detection biometric system. This end-to-end system would include a frontend for new user registration, verification of user fingervein and deletion.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We achieved this using a Fingervein device and a custom built secure backend database. All the services were defined as part of an API which was hosted on a cloud platform. All the information transfer was done after using encryption. Furthermore, the frontend was built as a Google Chrome extension and integrated right into the browser for easy usage. This would ensure scalability and hassle free adoption.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We were able to test out the full end-to-end pipeline right from registering new users and other management options provided to actually verifying the users based on the fingervein scans. This capability was built out and documented to be used for any future client engagements as a replacement for the traditional fingerprint security system.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Occupancy Detection</title>
      <link>https://prasang-gupta.github.io/project/occupancydetection/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/occupancydetection/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;PROBLEM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The client wanted to prepare for and ensure a safe transitioning of people from &amp;ldquo;Work from home&amp;rdquo; to Office space. They wanted to make sure that the facility should be used responsibly and at no time there should be breaches of the social distancing regulations.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;SOLUTION&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We prepared a solution that gave the client the ability to track and measure the occupancy and social distancing norms anonymously. We set up a LIDAR in the client office space attached with a hub to send the data to the cloud. Several calculations and checks were performed on the cloud and the final data was sent to the dashboard. The real time occupancy readings (both overall and zone-based) were also visualised by the dashboard.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As a result of our solution, the client could monitor occupancy in real-time, track occupancy trends and monitor the hotspots in the office. As an extension, this can further be used to optimise the office space usage.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Factory Intelligence</title>
      <link>https://prasang-gupta.github.io/project/factoryintelligence/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/factoryintelligence/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;PROBLEM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our client was facing unplanned machine downtimes in their factories. Obtaining insights from machinery on factory floors is time-consuming, complex, and costly due to legacy infrastructure and bespoke systems that cannot be easily accessed. Accelerating the time it takes to draw intelligence from machine data is critical to get an accurate pulse on manufacturing operations. While many vendors offer comprehensive IIoT solutions, we were looking for quicker and more cost-effective alternatives to deploying a sophisticated end-to-end platform.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;SOLUTION&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We designed, deployed and tested a fully-functioning prototype on our clientâs manufacturing floor in less than 4 weeks. Our solution utilized low-cost vibration sensors and accelerometers connected directly to selected machines. These sensors captured near real-time data and provided rapid analytics by bypassing timely integrations with existing factory systems.&lt;/p&gt;
&lt;p&gt;We also designed and built a customized dashboard offering a simple and elegant view of the captured insights. The insights present on the dashboard included machine schedules, unplanned downtimes, overall availability and the number of times the machine was stopped. All of this was reported and updated real-time with a resolution of 4 minutes.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Instead of spending months and significant budget to deploy an end-to-end IIoT platform, our client was equipped with critical insights in a much shorter timeframe. KPIs captured included machine up/downtime compared with scheduled operating times. The intelligence gathered not only provided efficiency gains and cost savings, but also avoided our client complex work orders to deploy sensory equipment. Consequently, client involvement was low-touch and the manufacturing process was not interrupted.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cross-country Asset Tracking</title>
      <link>https://prasang-gupta.github.io/project/assettracking/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/assettracking/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;PROBLEM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The client were facing problems with cargo damage while in transit which were resulting in huge losses for them. Also, since the transit included multiple contractors responsible for different stretches of the overall route, and nobody was taking responsibility for the damages, they were at a loss and had no idea how to rectify this.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;SOLUTION&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We created an end-to-end asset tracking system for the client. The clients were given low-cost devices housing different sensors to include them with their shipments. These devices were very small (about 2cm x 2cm x 1cm) and were tested for harsh weather. Also, these devices were equipped with a battery, a GPS and cellular communication technology along with the accelerometer, humidity and temperature sensors. These were configured to be used as one time use devices to save on device recovery costs / logistics. They were configured to report information all along the journey and last the whole shipment time without the need of a recharge.&lt;/p&gt;
&lt;p&gt;Thresholding was done on the accelerometer sensor housed in the device to store high impacts faced by it, which would directly correlate with the damage faced the equipment. These raw accelerometer values were then configured to be sent to the cloud managed by the manufacturer. This data was then available to be used using simple API requests.&lt;/p&gt;
&lt;p&gt;The raw data collection and conversion to impact system was built on an application enablement platform. This resulted in quick prototyping and testing of the proof of concept. The processed data was then sent to a live dahsboard which was shared with the client for their perusal. This dashboard offered several important metrics such as the last known location, temperature and battery of the device. It also showed the impact values versus timestamp which were recorded by the device.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;IMPACT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;From using this solution, we were able to ascertain different impact values faced by the device during different portions of the journey. This helped the client to visualise and piece together possible regions where the shipment was getting damaged. Our analysis found that most of the impacts registered by the device were when the device was travelling from the factory to the ports, which was contrary to the earlier belief of the client that most of the damage was being caused during the ship route. This allowed the client to focus on that section and helped them save a lot of revenue spent on replacing damaged products as well as save the reputation of the company.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Implementation of Live models on Edge</title>
      <link>https://prasang-gupta.github.io/project/edgelivemodels/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/edgelivemodels/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;AIM&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project was two fold. The first aim was to implement an action recognition model and the second was to modify it to run on an edge device. For this, we chose the Pre-trained Temporal Relation Network Model. The dataset chosen for this was the 20BN-something-something Dataset V2. This dataset has over 100 classes of different object-human or object-object interactions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;jetson.png&#34; alt=&#34;Jetson TX2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:#5DADE2;font-style:bold;font-size:120%&#34;&gt;DETAILS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The model was first implemented on a laptop with the webcam and then later extended onto the edge device, Jetson TX2. Prior to this, the TX2 was flashed and proper libraries were built from source to enable it to use its full potential (CUDA cores for rendering). We were successfully able to implement this on the board and were getting very respectable frame rates, somewhere around 10 fps. The performance of this model for several different scenarios can be seen in the videos link and a little detail about the implementation can be found in the slides.&lt;/p&gt;
&lt;p&gt;Apart from this, we also implemented simple object detection models on Raspberry Pi on which we were getting around 1-2 fps.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
