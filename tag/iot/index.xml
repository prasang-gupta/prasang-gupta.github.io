<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IoT | Prasang Gupta</title>
    <link>https://prasang-gupta.github.io/tag/iot/</link>
      <atom:link href="https://prasang-gupta.github.io/tag/iot/index.xml" rel="self" type="application/rss+xml" />
    <description>IoT</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 Prasang Gupta</copyright><lastBuildDate>Tue, 01 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://prasang-gupta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>IoT</title>
      <link>https://prasang-gupta.github.io/tag/iot/</link>
    </image>
    
    <item>
      <title>Occupancy Detection</title>
      <link>https://prasang-gupta.github.io/project/occupancydetection/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/occupancydetection/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;CLIENT PROBLEM&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The client wanted to prepare for and ensure a safe transitioning of people from &amp;ldquo;Work from home&amp;rdquo; to Office space. They wanted to make sure that the facility should be used responsibly and at no time there should be breaches of the social distancing regulations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;OUR SOLUTION&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We prepared a solution that gave the client the ability to track and measure the occupancy and social distancing norms anonymously. We set up a LIDAR in the client office space attached with a hub to send the data to the cloud. Several calculations and checks were performed on the cloud and the final data was sent to the dashboard. The real time occupancy readings (both overall and zone-based) were also visualised by the dashboard.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;VALUE GENERATED&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a result of our solution, the client could monitor occupancy in real-time, track occupancy trends and monitor the hotspots in the office. This can further be used to optimise the office space usage.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Factory Intelligence</title>
      <link>https://prasang-gupta.github.io/project/factoryintelligence/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/factoryintelligence/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;CLIENT PROBLEM&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our client was facing unplanned machine downtimes in their factories. Obtaining insights from machinery on factory floors is time-consuming, complex, and costly due to legacy infrastructure and bespoke systems that cannot be easily accessed. Accelerating the time it takes to draw intelligence from machine data is critical to get an accurate pulse on manufacturing operations. While many vendors offer comprehensive IIoT solutions, we were looking for quicker and more cost-effective alternatives to deploying a sophisticated end-to-end platform.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;OUR SOLUTION&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We designed, deployed and tested a fully-functioning prototype on our client’s manufacturing floor in less than 4 weeks. Our solution utilized low-cost vibration sensors and accelerometers connected directly to selected machines. These sensors captured near real-time data and provided rapid analytics by bypassing timely integrations with existing factory systems.&lt;/p&gt;
&lt;p&gt;We also designed and built a customized dashboard offering a simple and elegant view of the captured insights. The insights present on the dashboard included machine schedules, unplanned downtimes, overall availability and the number of times the machine was stopped. All of this was reported and updated real-time with a resolution of 4 minutes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;VALUE GENERATED&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Instead of spending months and significant budget to deploy an end-to-end IIoT platform, our client was equipped with critical insights in a much shorter timeframe. KPIs captured included machine up/downtime compared with scheduled operating times. The intelligence gathered not only provided efficiency gains and cost savings, but also avoided our client complex work orders to deploy sensory equipment. Consequently, client involvement was low-touch and the manufacturing process was not interrupted.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fingervein Detection</title>
      <link>https://prasang-gupta.github.io/project/fingervein/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/fingervein/</guid>
      <description>&lt;p&gt;The aim of this project was to build out a fully functional proof of concept for the fingervein detection biometric system. This end-to-end system would include a frontend for new user registration, verification of user fingervein and deletion. We achieved this using a Fingervein device and a custom built secure backend database.&lt;/p&gt;
&lt;p&gt;All the services were defined as part of an API which was hosted on a cloud platform. All the information transfer was done after using encryption. Furthermore, the frontend was built as a Google Chrome extension and integrated right into the browser for easy usage. This would ensure scalability and hassle free adoption.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cross-country Asset Tracking</title>
      <link>https://prasang-gupta.github.io/project/assettracking/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/assettracking/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;CLIENT PROBLEM&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The client were facing problems with cargo damage while in transit which were resulting in huge losses for them. Also, since the transit included multiple contractors responsible for different stretches of the overall route, and nobody was taking responsibility for the damages, they were at a loss and had no idea how to rectify this.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;OUR SOLUTION&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;Solution Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;We created an end-to-end asset tracking system for the client. The clients were given low-cost devices housing different sensors to include them with their shipments. These devices were very small (about 2cm x 2cm x 1cm) and were tested for harsh weather. Also, these devices were equipped with a battery, a GPS and cellular communication technology along with the accelerometer, humidity and temperature sensors. These were configured to be used as one time use devices to save on device recovery costs / logistics. They were configured to report information all along the journey and last the whole shipment time without the need of a recharge.&lt;/p&gt;
&lt;p&gt;Thresholding was done on the accelerometer sensor housed in the device to store high impacts faced by it, which would directly correlate with the damage faced the equipment. These raw accelerometer values were then configured to be sent to the cloud managed by the manufacturer. This data was then available to be used using simple API requests.&lt;/p&gt;
&lt;p&gt;The raw data collection and conversion to impact system was built on an application enablement platform. This resulted in quick prototyping and testing of the proof of concept. The processed data was then sent to a live dahsboard which was shared with the client for their perusal. This dashboard offered several important metrics such as the last known location, temperature and battery of the device. It also showed the impact values versus timestamp which were recorded by the device.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;VALUE GENERATED&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From using this solution, we were able to ascertain different impact values faced by the device during different portions of the journey. This helped the client to visualise and piece together possible regions where the shipment was getting damaged. Our analysis found that most of the impacts registered by the device were when the device was travelling from the factory to the ports, which was contrary to the earlier belief of the client that most of the damage was being caused during the ship route. This allowed the client to focus on that section and helped them save a lot of revenue spent on replacing damaged products as well as save the reputation of the company.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Implementation of Live models on Edge</title>
      <link>https://prasang-gupta.github.io/project/edgelivemodels/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://prasang-gupta.github.io/project/edgelivemodels/</guid>
      <description>&lt;p&gt;The aim of this project was two fold. The first aim was to get the action recognition model running and the second was to implement the same on an edge device. For this, we chose the Pre-trained Temporal Relation Network Model from &lt;a href=&#34;https://github.com/zhoubolei/TRN-pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. The dataset chosen for this was the &lt;a href=&#34;https://20bn.com/datasets/something-something/v2#download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;20BN-something-something Dataset V2&lt;/a&gt;. This dataset has over 100 classes of different object-human or object-object interactions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;jetson.png&#34; alt=&#34;Jetson TX2&#34;&gt;&lt;/p&gt;
&lt;p&gt;The model was first implemented on a laptop with the webcam and then later extended onto the edge device, Jetson TX2. Prior to this, the TX2 was flashed and proper libraries were built from source to enable it to use its full potential (CUDA cores for rendering). We were successfully able to implement this on the board and were getting very respectable frame rates, somewhere around 10 fps. The performance of this model for several different scenarios can be seen in the videos link and a little detail about the implementation can be found in the slides.&lt;/p&gt;
&lt;p&gt;Apart from this, we also implemented simple object detection models on Raspberry Pi on which we were getting around 1-2 fps.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
